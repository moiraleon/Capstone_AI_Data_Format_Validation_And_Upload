{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (1.35.13)\n",
      "Requirement already satisfied: python-dotenv in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/moleon/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Conversion complete! Chat-formatted data saved to 'data/chat_dataset.jsonl'\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.File, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Upload the training file\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/chat_dataset.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 49\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpurpose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine-tune\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m training_file_id \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining file ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_file_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Caspstone_AI_Data_Format_Validation/myenv/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.File, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# Ensure that openai and python-dotenv are installed in the Jupyter Notebook environment\n",
    "%pip install --upgrade openai python-dotenv\n",
    "\n",
    "# Import necessary libraries\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Load your existing dataset\n",
    "with open('../data/mvp_dataset.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to chat format\n",
    "chat_data = []\n",
    "\n",
    "for entry in data:\n",
    "    user_message = None\n",
    "    assistant_message = None\n",
    "    for message in entry['messages']:\n",
    "        if message['role'] == 'user':\n",
    "            user_message = message['content']\n",
    "        elif message['role'] == 'assistant':\n",
    "            assistant_message = json.dumps(message['content'])  # Serialize the content to a string\n",
    "    \n",
    "    if user_message and assistant_message:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_message}\n",
    "        ]\n",
    "        chat_data.append({\"messages\": messages})\n",
    "\n",
    "# Save the new dataset in JSONL format\n",
    "with open('../data/chat_dataset.jsonl', 'w') as f:\n",
    "    for item in chat_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(\"Conversion complete! Chat-formatted data saved to 'data/chat_dataset.jsonl'\")\n",
    "\n",
    "# Upload the training file\n",
    "with open(\"../data/chat_dataset.jsonl\", \"rb\") as file:\n",
    "    response = openai.File.create(\n",
    "        file=file,\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "training_file_id = response['id']\n",
    "print(f\"Training file ID: {training_file_id}\")\n",
    "\n",
    "# Verify the file upload\n",
    "file_info = openai.File.retrieve(training_file_id)\n",
    "print(file_info)\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune_response = openai.FineTune.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\"  # Ensure you use the correct model ID\n",
    ")\n",
    "fine_tune_id = fine_tune_response['id']\n",
    "print(f\"Fine-tuning job ID: {fine_tune_id}\")\n",
    "\n",
    "# Check the status of the fine-tuning job\n",
    "status = openai.FineTune.retrieve(fine_tune_id)\n",
    "print(status)\n",
    "\n",
    "# Optionally, monitor the fine-tuning process\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    status = openai.FineTune.retrieve(fine_tune_id)\n",
    "    status_str = status['status']\n",
    "    print(f\"Fine-tuning status: {status_str}\")\n",
    "    return status_str\n",
    "\n",
    "# Monitor the fine-tuning job until it's done\n",
    "while True:\n",
    "    status_str = check_fine_tune_status(fine_tune_id)\n",
    "    if status_str not in ['pending', 'running']:\n",
    "        break\n",
    "    time.sleep(60)  # Wait for 60 seconds before checking the status again\n",
    "\n",
    "# Use the fine-tuned model once the fine-tuning is complete\n",
    "if status_str == 'succeeded':\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=fine_tune_id,  # Use the ID of the fine-tuned model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Provide a lesson plan on Introduction to Addition and Subtraction suitable for students with Dyslexia and ADHD, for Kindergarten through Grade 2.\"}\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    print(response['choices'][0]['message']['content'])\n",
    "else:\n",
    "    print(\"Fine-tuning did not succeed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
